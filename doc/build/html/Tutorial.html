
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="zh_CN">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>NAS-project教程 &#8212; NAS-Project  文档</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/translations.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="运行日志" href="log.html" />
    <link rel="prev" title="工程概述" href="project.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="nas-project">
<h1>NAS-project教程<a class="headerlink" href="#nas-project" title="永久链接至标题">¶</a></h1>
<div class="section" id="id1">
<h2>快速上手<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<div class="section" id="id2">
<h3>运行环境要求<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h3>
<p>本工程要求的运行环境如下：</p>
<ul class="simple">
<li>Python版本3.6及以上</li>
<li>tensorflow-gpu,版本1.13或1.14</li>
<li>numpy</li>
<li>keras</li>
</ul>
</div>
<div class="section" id="id3">
<h3>一个简单的例子<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>本部分我们先以实现 <code class="docutils literal notranslate"><span class="pre">cifar-10分类任务</span></code> 的NAS工程为例，说明如何启动整个NAS工程。</p>
<div class="section" id="id4">
<h4>1. 定义任务<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<div class="section" id="id5">
<h5>(1). 读入数据<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h5>
<p>在 <a class="reference external" href="../../../evaluator.py">evaluator.py</a> 中实现cifar-10的读入和处理。</p>
<p>1). 给定任务数据的描述</p>
<p>定义 <code class="docutils literal notranslate"><span class="pre">Evaluator.__init__</span></code> 函数中的参数</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_class</span><span class="p">]</span>
</pre></div>
</div>
<p>2). 完成数据读入</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> 类中实现 <code class="docutils literal notranslate"><span class="pre">input()</span></code> 方法，返回cifar-10的训练和测试数据集 <code class="docutils literal notranslate"><span class="pre">self.train_data</span></code> ,
<code class="docutils literal notranslate"><span class="pre">self.train_label</span></code> , <code class="docutils literal notranslate"><span class="pre">self.test_data</span></code> , <code class="docutils literal notranslate"><span class="pre">self.test_label</span></code> ，返回类型为list。</p>
</div>
<div class="section" id="evaluator-eval">
<h5>(2). 定义Evaluator._eval函数<a class="headerlink" href="#evaluator-eval" title="永久链接至标题">¶</a></h5>
<p>利用本函数的给定输入进行计算，返回规定输出。</p>
<p>输入参数：</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">sess</span></code>：Tensorflow Session</li>
<li><code class="docutils literal notranslate"><span class="pre">logits</span></code>：Tensorflow Tensor; 网络模型的最后一层输出，注意可能需要进一步处理。</li>
<li><code class="docutils literal notranslate"><span class="pre">data_x</span></code>：Tensorflow Placeholder; 网络的输入</li>
<li><code class="docutils literal notranslate"><span class="pre">data_y</span></code>：Tensorflow Placeholder; 真实标签</li>
</ul>
</div></blockquote>
<p>1). 利用logits计算具体结果</p>
<p>logits为搜索网络得到的输出，为了得到最终结果需要将其经过一层全连接层，将维度压缩至输出大小</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_makedense</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="s1">&#39;&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>2). 定义loss的计算方式、梯度的更新方式</p>
<p>定义loss，建议将计算loss的方法封装为一个函数</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
     <span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
         <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">))</span>
     <span class="n">l2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()])</span>
     <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy</span> <span class="o">+</span> <span class="n">l2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span>
     <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>定义train_op：</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_train_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_num</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="n">decay_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_batches_per_epoch</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">cosine_decay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">INITIAL_LEARNING_RATE</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>

    <span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Momentum&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_num</span><span class="p">),</span>
                                     <span class="n">use_nesterov</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">update_ops</span><span class="p">):</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_op</span>
</pre></div>
</div>
<p><strong>注意</strong> 这里一定要加上tf.GraphKeys.UPDATE_OPS的依赖，具体原因可见 <code class="docutils literal notranslate"><span class="pre">实现自定义任务</span></code> 章节下的 <a class="reference internal" href="#loss">(2) 定义loss的计算方式、梯度的更新方式</a> 。</p>
<p>3). 定义返回的目标值</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="s2">&quot;float&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>4). 启动 <code class="docutils literal notranslate"><span class="pre">sess.run()</span></code></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">log</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

<span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_num</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_label</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">()</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span>
                                      <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">data_x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">data_y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">,</span> <span class="n">train_flag</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_y</span> <span class="o">=</span> <span class="n">test_label</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">l</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span>
                           <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">data_x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">data_y</span><span class="p">:</span> <span class="n">batch_y</span><span class="p">,</span> <span class="n">train_flag</span><span class="p">:</span> <span class="bp">False</span><span class="p">})</span>
        <span class="n">precision</span> <span class="o">+=</span> <span class="n">acc</span> <span class="o">/</span> <span class="n">num_iter</span>

    <span class="n">log</span> <span class="o">+=</span> <span class="s1">&#39;epoch </span><span class="si">%d</span><span class="s1">: precision = </span><span class="si">%.3f</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>

<span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">log</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">acc</span></code> 、 <code class="docutils literal notranslate"><span class="pre">loss_value</span></code> 即为训练过程中的准确率和loss。</p>
<p><strong>注意</strong> 这里的self.epoch和self.train_num是不可自定义的，且必须使用这两个值。</p>
</div>
</div>
<div class="section" id="id6">
<h4>2. 定义搜索空间<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h4>
<p>搜索空间包括 <code class="docutils literal notranslate"><span class="pre">拓扑结构</span></code> 和 <code class="docutils literal notranslate"><span class="pre">操作算子</span></code> 两个。</p>
<div class="section" id="id7">
<h5>(1). 定义拓扑结构<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h5>
<p>此处设定搜索网络block的深度和宽度。假设想要搜索深度为5、宽度为3的block，且支链上的节点不超过2，只需在 <a class="reference external" href="../../../nas_config.json">nas_config.json</a>
中修改：</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;enum&quot;</span><span class="p">:{</span>
  <span class="s2">&quot;depth&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
  <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
  <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="mi">2</span>
  <span class="p">}</span>
</pre></div>
</div>
<p>还可以在下方设置最大跨层长度和最大跨层个数：</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;spl&quot;</span><span class="p">:{</span>
<span class="s2">&quot;skip_max_dist&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
<span class="s2">&quot;skip_max_num&quot;</span><span class="p">:</span> <span class="mi">3</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id8">
<h5>(2). 定义操作算子<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h5>
<p>注意这个部分可选，因为我们已经实现了部分操作，详见 <a class="reference internal" href="#id19">2. 修改操作配置</a> .</p>
<p>假设现在要加入卷积（Convolution）操作到神经网络，其中包含filter_size、kernel_size和激活函数类型几个参数。
设定几个参数的取值范围为：</p>
<ul class="simple">
<li>filter_size: 32, 48, 64</li>
<li>kernel_size: 1, 3, 5</li>
<li>激活函数类型：relu, leakyrelu, relu6</li>
</ul>
<p>(1). 首先在 <code class="docutils literal notranslate"><span class="pre">nas_config.json/spl/space</span></code> 下按如下格式添加卷积操作的搜索空间：</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;conv&quot;</span><span class="p">:</span> <span class="p">{</span>
  <span class="s2">&quot;filter_size&quot;</span><span class="p">:</span> <span class="p">[</span>   <span class="mi">32</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">64</span>   <span class="p">],</span>
  <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="p">[</span>     <span class="mi">1</span><span class="p">,</span>     <span class="mi">3</span><span class="p">,</span>     <span class="mi">5</span>   <span class="p">],</span>
  <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>     <span class="s2">&quot;leakyrelu&quot;</span><span class="p">,</span>     <span class="s2">&quot;relu6&quot;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>(2). 参考 <a class="reference external" href="../../../evaluator.py">evaluator.py</a> ，在 <code class="docutils literal notranslate"><span class="pre">Evaluator._make_layer</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">elif</span></code> 下添加新的操作类型，格式如下</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">cell</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;conv&#39;</span><span class="p">:</span>
     <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_makeconv</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
</pre></div>
</div>
<p>然后定义具体操作对应的函数</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_makeconv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">conv_layer</span>
</pre></div>
</div>
<p>具体示范参见 <a class="reference external" href="../../../evaluator.py">evaluator.py</a> 中 <code class="docutils literal notranslate"><span class="pre">_makeconv</span></code> 函数的具体实现。</p>
</div>
</div>
<div class="section" id="id9">
<h4>3. 启动搜索算法<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h4>
<p>(1). 运行</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python nas.py
</pre></div>
</div>
<p>或在新建python文件中输入</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">from</span> <span class="nn">info_str</span> <span class="kn">import</span> <span class="n">NAS_CONFIG</span>
<span class="kn">from</span> <span class="nn">nas</span> <span class="kn">import</span> <span class="n">NAS</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">NUM_GPU</span> <span class="o">=</span> <span class="n">NAS_CONFIG</span><span class="p">[</span><span class="s1">&#39;nas_main&#39;</span><span class="p">][</span><span class="s2">&quot;num_gpu&quot;</span><span class="p">]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">NUM_GPU</span><span class="p">,</span> <span class="n">maxtaskperchild</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nas</span> <span class="o">=</span> <span class="n">Nas</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">best_nn</span> <span class="o">=</span> <span class="n">nas</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">best_nn</span></code> 即为最佳网络</p>
<p>(2). 运行过程中的评估信息、中间结果等日志保存在 <code class="docutils literal notranslate"><span class="pre">memory</span></code> 文件夹下。详见 <a class="reference external" href="log.html">运行日志</a> .</p>
<p>代码文件夹中附带的 <a class="reference external" href="../../../evaluator_classification.py">evaluator_classification.py</a> 实现了cifar-10的分类任务，
需要运行的话只需将文件名重命名为evaluator.py，然后按照步骤(5)启动搜索算法即可。如需定义更为复杂的任务，更多详细内容请
参照 <a class="reference internal" href="#id11">实现自定义任务</a> 以及 <a class="reference internal" href="#id17">改变搜索空间</a> 中的内容。</p>
</div>
</div>
</div>
<div class="section" id="id10">
<h2>如何实现自定义搜索<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h2>
<div class="section" id="id11">
<h3>实现自定义任务<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h3>
<p>这一步需要修改的函数集中在 <a class="reference external" href="../../../evaluator.py">evaluator.py</a> 中。在完成本步骤之前evaluator.py无法运行。
实现自定义的任务，需要以下几个步骤：</p>
<div class="section" id="id12">
<h4>1. 任务数据的读入与处理。<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h4>
<div class="section" id="id13">
<h5>(1) 给定任务数据的描述<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h5>
<p>这一步需要修改 <code class="docutils literal notranslate"><span class="pre">Evaluator.__init__</span></code> 函数中的参数</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">self.input_shape</span></code> : list, list中为int; 输入数据尺寸，一般情况下为[batch_size, H, W, C]，其中H，W，C为图片尺寸</li>
<li><code class="docutils literal notranslate"><span class="pre">self.output_shape</span></code> : list, list中为int; 输出数据尺寸。</li>
</ul>
<p>注意 <code class="docutils literal notranslate"><span class="pre">Evaluator.__init__</span></code> 函数中其他的已有参数不需要修改。如果有训练任务中需要的其他参数也可以在这里定义。</p>
</div>
<div class="section" id="id14">
<h5>(2) 完成数据的读入与处理<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h5>
<p>数据在 <code class="docutils literal notranslate"><span class="pre">Evaluator.__init__</span></code> 函数中的 <code class="docutils literal notranslate"><span class="pre">self.train_data</span></code> , <code class="docutils literal notranslate"><span class="pre">self.train_label</span></code> ,
<code class="docutils literal notranslate"><span class="pre">self.test_data</span></code> , <code class="docutils literal notranslate"><span class="pre">self.test_label</span></code> 中，
这几个参数的返回类型建议为 <code class="docutils literal notranslate"><span class="pre">list</span></code> ，也可以根据任务稍作修改。</p>
<p><strong>注意数据必须在Evaluator类初始化时读入</strong> ，防止在后期枚举网络时重复读入数据耗时大。
建议将跟数据相关的函数封装为一个类， <a class="reference external" href="../../../evaluator_classification.py">evaluator_classification.py</a> 中提供了一个示范。</p>
</div>
</div>
<div class="section" id="id15">
<h4>2. 修改 <code class="docutils literal notranslate"><span class="pre">Evaluator._eval</span></code> 函数<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h4>
<p>由于具体的任务对应的评估训练方式可能不同，这里具体的评估方式也需自行实现。具体只需要修改 <code class="docutils literal notranslate"><span class="pre">Evaluator._eval</span></code> 函数。
本函数的输入和输出已经固定。</p>
<ul>
<li><p class="first"><code class="docutils literal notranslate"><span class="pre">Evaluator._eval</span></code></p>
<blockquote>
<div><p>输入参数：</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">sess</span></code>：Tensorflow Session; 其中网络构图已经载入Tensorflow，需要利用 <code class="docutils literal notranslate"><span class="pre">sess.run()</span></code> 启动训练过程</li>
<li><code class="docutils literal notranslate"><span class="pre">logits</span></code>：Tensorflow Tensor; 网络模型的预测输出，注意可能需要进一步处理。</li>
<li><code class="docutils literal notranslate"><span class="pre">data_x</span></code>：Tensorflow Placeholder; 网络的样本（或称特征）输入，可以通过feet_dict的方式将数据输入计算图中，如果对tensorflow的机制不熟悉需要注意 <code class="docutils literal notranslate"><span class="pre">data_x</span></code> 与 <code class="docutils literal notranslate"><span class="pre">self.train_data</span></code> 的区别和联系。</li>
<li><code class="docutils literal notranslate"><span class="pre">data_y</span></code>：Tensorflow Placeholder; 网络的真实标签，可以通过feet_dict的方式将数据输入计算图中</li>
</ul>
</div></blockquote>
<p>输出参数：</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">target</span></code>：float；网络的评估值。可以是单纯的准确率，或者多目标综合的结果（如综合考虑准确率和模型大小）</li>
<li><code class="docutils literal notranslate"><span class="pre">log</span></code>：string；可为空，需要打印的日志信息</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
</ul>
<p>本函数主要利用 <code class="docutils literal notranslate"><span class="pre">sess.run()</span></code> 启动训练过程返回评估值。</p>
<div class="section" id="logits">
<h5>(1) 利用logits计算具体结果<a class="headerlink" href="#logits" title="永久链接至标题">¶</a></h5>
<p>这里需要注意logits不一定表示最终输出，只是表示搜索的网络得出的输出。</p>
<p>比如在 <code class="docutils literal notranslate"><span class="pre">分类问题</span></code> 中，logits为卷积和池化等操作的输出，还需经过一层全连接将logits由原来的四维压缩为两维，即[batch_size,num_class]大小。
详见 <a class="reference external" href="../../../evaluator_classification.py">evaluator_classification.py</a> 的 <code class="docutils literal notranslate"><span class="pre">_eval</span></code> 函数的示例。</p>
<p>再比如在 <code class="docutils literal notranslate"><span class="pre">图片去噪</span></code> 问题中，最后需要将图片还原成原来的尺寸，需要在最后一层加一个输出channel为3的卷积层，都需要在这里添加。</p>
</div>
<div class="section" id="loss">
<h5>(2) 定义loss的计算方式、梯度的更新方式<a class="headerlink" href="#loss" title="永久链接至标题">¶</a></h5>
<p>在</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">data_y</span><span class="p">)</span>
</pre></div>
</div>
<p>中定义 <code class="docutils literal notranslate"><span class="pre">loss</span></code> 的计算。</p>
<p>在</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_op</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>中定义梯度的更新方式，返回 <code class="docutils literal notranslate"><span class="pre">train_op</span></code> 。这里需要注意由于搜索的算子中有 <code class="docutils literal notranslate"><span class="pre">batch_norm</span></code> 的计算， <code class="docutils literal notranslate"><span class="pre">train_op</span></code>
的计算需要添加依赖，即</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">update_ops</span><span class="p">):</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">)</span>
</pre></div>
</div>
<p>具体原理可参见 <a class="reference external" href="http://www.jianshu.com/p/437fb1a5823e">此处</a> 。</p>
</div>
<div class="section" id="id16">
<h5>(3) 定义返回的目标值<a class="headerlink" href="#id16" title="永久链接至标题">¶</a></h5>
<p>在</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cal_accuracy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">data_y</span><span class="p">)</span>
</pre></div>
</div>
<p>中定义任务的目标。</p>
</div>
<div class="section" id="sess-run">
<h5>(4) 启动 <code class="docutils literal notranslate"><span class="pre">sess.run()</span></code><a class="headerlink" href="#sess-run" title="永久链接至标题">¶</a></h5>
<p>我们的数据输入方式是定义 <code class="docutils literal notranslate"><span class="pre">tf.placeholder</span></code> 后通过feet_dict的方式输入，即</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acc</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">train_op</span><span class="p">,</span> <span class="n">feet_dict</span><span class="o">=</span><span class="p">{</span><span class="n">data_x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">data_y</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_label</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]})</span>
</pre></div>
</div>
<p>其中 <code class="docutils literal notranslate"><span class="pre">acc</span></code> 、 <code class="docutils literal notranslate"><span class="pre">loss_value</span></code> 分别为训练过程中的准确率和loss。</p>
<p><strong>注意</strong> 训练中的epoch数不可自定义，需使用self.epoch。而每一个epoch中训练的循环（iteration）不可使用固定数据集
大小，需使用self.train_num。举例来说，cifar-10数据集的训练集大小为50000，则每一个epoch应循环50000/batch_size次，
但这里不可使用50000，而应使用self.train_num，也就是训练应循环self.train_num/batch_size次。
<a href="#id21"><span class="problematic" id="id22">`(2). 修改Evaluator._eval函数`_</span></a> 提供了一个示例。</p>
</div>
</div>
</div>
<div class="section" id="id17">
<h3>改变搜索空间<a class="headerlink" href="#id17" title="永久链接至标题">¶</a></h3>
<p>算法原理中概述了我们的搜索空间分为两个部分：拓扑结构和操作配置。其中拓扑结构即为网络拓扑结构，操作配置即为基本算子。</p>
<div class="section" id="id18">
<h4>1. 修改拓扑结构<a class="headerlink" href="#id18" title="永久链接至标题">¶</a></h4>
<p>拓扑结构的修改主要是网络的深度和宽度，本部分修改的内容集中在 <a class="reference external" href="../../../nas_config.json">nas_config.json</a>
中，仅需修改几个数字即可控制网络拓扑结构的范围。</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>enum 穷举模块参数</dt>
<dd><ul class="first last">
<li>depth 枚举的网络结构的深度</li>
<li>width 枚举的网络结构的支链个数</li>
<li>max_depth 约束支链上节点的最大个数</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>spl 采样参数</dt>
<dd><ul class="first last">
<li>skip_max_dist 最大跨层长度</li>
<li>skip_max_num 最大跨层个数</li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>如果对这部分有疑问可以参见 <a class="reference external" href="project.html">此页</a> 的图.</p>
</div>
<div class="section" id="id19">
<h4>2. 修改操作配置<a class="headerlink" href="#id19" title="永久链接至标题">¶</a></h4>
<p>注意这个部分是可选的，因为我们已经实现了一部分操作，包括：卷积操作（ <code class="docutils literal notranslate"><span class="pre">tf.nn.conv2d</span></code> ）、分离卷积（ <code class="docutils literal notranslate"><span class="pre">tf.nn.separable_conv2d</span></code> ）、
池化操作（包括最大池化 <code class="docutils literal notranslate"><span class="pre">tf.nn.max_pool</span></code> 、平均池化 <code class="docutils literal notranslate"><span class="pre">tf.nn.avg_pool</span></code> 和全局池化 <code class="docutils literal notranslate"><span class="pre">global_pooling</span></code> ），其中卷积操作和分离卷积
都包含 <code class="docutils literal notranslate"><span class="pre">batch_norm</span></code> 操作。如果不需要添加新的操作则不需要对这个部分做改动即可运行。</p>
<p>本部分修改的内容集中在 <a class="reference external" href="../../../nas_config.json">nas_config.json</a> 和 <a class="reference external" href="../../../evaluator.py">evaluator.py</a> 中。</p>
<div class="section" id="nas-config-json">
<h5>(1). 修改 <a class="reference external" href="../../../nas_config.json">nas_config.json</a><a class="headerlink" href="#nas-config-json" title="永久链接至标题">¶</a></h5>
<p>修改nas_config.json/spl/space，在其下按如下格式添加新操作的搜索空间：</p>
<blockquote>
<div><div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;operation_name&quot;</span><span class="p">:{</span>
<span class="s2">&quot;param1&quot;</span><span class="p">:</span> <span class="p">[</span>   <span class="n">value1</span><span class="p">,</span> <span class="n">value2</span><span class="o">...</span>   <span class="p">],</span>
<span class="s2">&quot;param2&quot;</span><span class="p">:</span> <span class="p">[</span>     <span class="n">value1</span><span class="p">,</span>  <span class="n">value2</span><span class="o">...</span>  <span class="p">],</span>
<span class="o">...</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="evaluator-py">
<h5>(2). 修改 <a class="reference external" href="../../../evaluator.py">evaluator.py</a><a class="headerlink" href="#evaluator-py" title="永久链接至标题">¶</a></h5>
<p>在Evaluator._make_layer中的elif下添加新的操作类型，格式如下</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">cell</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;operation_name&#39;</span><span class="p">:</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name_your_function_here</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
</pre></div>
</div>
<p>然后定义具体操作对应的函数</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_name_your_function_here</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
    <span class="c1"># TODO add your function here if any new operation was added, see _makeconv as an example</span>
    <span class="k">return</span> <span class="n">layer</span>
</pre></div>
</div>
<p>此函数命名需要自己填写，但其输出必须为Tensorflow Tensor类型。输入参数含义如下：</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">inputs</span></code> ：Tensorflow Tensor；输入</li>
<li><code class="docutils literal notranslate"><span class="pre">cell</span></code> ：Cell类；包含操作配置信息</li>
<li><code class="docutils literal notranslate"><span class="pre">node</span></code> ：int；当前操作的节点编号，用于对操作节点的op进行唯一命名</li>
</ul>
</div>
</div>
</div>
<div class="section" id="id20">
<h3>其他可以修改的参数<a class="headerlink" href="#id20" title="永久链接至标题">¶</a></h3>
<p>在nas_config.json/nas_main中还有其他可以修改的参数，用以适用具体的任务或与运行环境相匹配。下面介绍一下这些参数以及其具体含义和作用。</p>
<ul class="simple">
<li>num_gpu 运行环境GPU个数</li>
<li>block_num 堆叠网络块数量，详细可见 <a class="reference external" href="project.html">此页</a> 图中的编号4</li>
<li>repeat_search 模块重复次数，详细可见 <a class="reference external" href="project.html">此页</a> 图中的编号5</li>
<li>link_node 连接节点类型，详细可见 <a class="reference external" href="project.html">此页</a> 图中的编号6</li>
<li>add_data_per_round 每一轮竞赛增加数据大小</li>
<li>add_data_for_winner 竞赛胜利者的训练数据集大小(-1代表使用全部数据)</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">內容目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">NAS-project教程</a><ul>
<li><a class="reference internal" href="#id1">快速上手</a><ul>
<li><a class="reference internal" href="#id2">运行环境要求</a></li>
<li><a class="reference internal" href="#id3">一个简单的例子</a><ul>
<li><a class="reference internal" href="#id4">1. 定义任务</a><ul>
<li><a class="reference internal" href="#id5">(1). 读入数据</a></li>
<li><a class="reference internal" href="#evaluator-eval">(2). 定义Evaluator._eval函数</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">2. 定义搜索空间</a><ul>
<li><a class="reference internal" href="#id7">(1). 定义拓扑结构</a></li>
<li><a class="reference internal" href="#id8">(2). 定义操作算子</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id9">3. 启动搜索算法</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id10">如何实现自定义搜索</a><ul>
<li><a class="reference internal" href="#id11">实现自定义任务</a><ul>
<li><a class="reference internal" href="#id12">1. 任务数据的读入与处理。</a><ul>
<li><a class="reference internal" href="#id13">(1) 给定任务数据的描述</a></li>
<li><a class="reference internal" href="#id14">(2) 完成数据的读入与处理</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id15">2. 修改 <code class="docutils literal notranslate"><span class="pre">Evaluator._eval</span></code> 函数</a><ul>
<li><a class="reference internal" href="#logits">(1) 利用logits计算具体结果</a></li>
<li><a class="reference internal" href="#loss">(2) 定义loss的计算方式、梯度的更新方式</a></li>
<li><a class="reference internal" href="#id16">(3) 定义返回的目标值</a></li>
<li><a class="reference internal" href="#sess-run">(4) 启动 <code class="docutils literal notranslate"><span class="pre">sess.run()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id17">改变搜索空间</a><ul>
<li><a class="reference internal" href="#id18">1. 修改拓扑结构</a></li>
<li><a class="reference internal" href="#id19">2. 修改操作配置</a><ul>
<li><a class="reference internal" href="#nas-config-json">(1). 修改 nas_config.json</a></li>
<li><a class="reference internal" href="#evaluator-py">(2). 修改 evaluator.py</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id20">其他可以修改的参数</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="project.html" title="上一章">工程概述</a></li>
      <li>Next: <a href="log.html" title="下一章">运行日志</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/Tutorial.rst.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="转向" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, NJU.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/Tutorial.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>